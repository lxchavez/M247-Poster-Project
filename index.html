<!DOCTYPE html>
<html>
  <head>
    <title>Predicting Outcomes With Markov Chains</title>
    <meta charset="utf-8"> 
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="http://netdna.bootstrapcdn.com/bootstrap/3.0.2/css/bootstrap.min.css">
    <link href='http://fonts.googleapis.com/css?family=Varela+Round|Open+Sans:300italic,400italic,600italic,700italic,800italic,400,700,800,600,300' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="container">
      
      <div class="row">
        <div class="page-header">
          <h1 id="title">Predicting Outcomes With Markov Chains <small class="pull-right" id="names">Alex, Bryce, Daniel, Katrina, Tae</small></h1>
        </div>
      </div>
      
      <div class="row">
        <div class="col-md-4">
          <h2 class="text-center">INTRODUCTION</h2>
          <p>
            <em>Markov Chains</em> are one of the most widely used applications of Linear Algebra.  It consists of a
            stochastic model describing a sequence of possible events in which the probability of each event
            depends only on the state attained in the previous event. A basic understanding of a Markov Chain
            consists of a current state, often compiled into a state vector c, and a stochastic matrix P, an
            nxn collection of probability vectors based on the number of states (n). The current state is used
            for the basis of the future states. The resulting Markov Chain is thus formed
            where where c<sub>1</sub> = Pc<sub>0</sub>, c<sub>2</sub> = Pc<sub>1</sub>,...,
            c<sub>(k+1)</sub> = Pc<sub>k</sub>, where k is an integer.
          </p>            
          <p>
            In this presentation we will show how Markov Chains can be used to determine the results for a future
            event, and is reliable enough for many real-world processes, but may not always be the best method. 
            Two such processes we will analyze here are weather forecasting and gambling predictions.
          </p>
          <p>
            <strong>Objectives</strong>
            <ol>
              <li>Understand the nature of Markov’s chain and it’s stability with different situations
</li>
              <li>Understand how the probability evolves with the chain
</li>
            </ol>
          </p>
<!--          <img class="img-thumbnail" src="images/weather_state_diagram.png">-->
          
          <h2 class="text-center">METHODOLOGY</h2>
          
          <h3 class="methodology-subheading text-center">EXAMPLE #1 - THIS WEEK'S WEATHER</h3>
          <p>
            Suppose that tomorrow’s weather only relies on today’s weather, and does not rely on any previous
            days. Given the tendencies of the December weather in Long Beach, the following stochastic matrix
            was created using data from December 2012 in the Farmer’s Almanac.
          </p>
          <p><img class="img-rounded" src="images/weather_1.png"></p>
          <p>Today’s weather (Monday, December 2, 2013) determined by observation:</p>
          <p><img class="img-rounded" src="images/weather_2.png"></p>
          <p>
            To predict the weather of any future day, simply raise P to the desired state vector, e.g. one would
            calculate the following to find Friday (x<sub>4</sub>):</p>
          <p><img class="img-rounded" src="images/weather_4.png"></p>
          
        </div>
        <div class="col-md-4">

          
          <h3 class="methodology-subheading text-center">EXAMPLE #2 - GAMBLIN' YOUR LUNCH MONEY</h3>
          <p>
            There exists a generous gambling game with probability .48 winning $1 on any turn, but .52 chance
            you will lose $1. It is free to play, but you must have at least $1 up to $4. You start with $1,
            and the game stops when you are either broke (lose) or have $5 (win).
          </p>
          <p>
            <strong>Important questions to answer:</strong>
            <ul>
              <li>Should you play?</li>
              <li>What is the probability you win $5 or go broke?</li>
              <li>How do your chances of winning change if you start with more money?</li>
            </ul>
          </p>
        
          <p>Stochastic Matrix for the generous gambling machine:</p>
          <p><img class="img-rounded" src="images/stochastic_matrix.png"></p>
        
<!--
          <p><strong>What happens if you start with $1?</strong></p>
          <p><img class="img-rounded" src="images/one_dollar.png"></p>
          <p><strong>What happens if you start with $4?</strong></p>
          <p><img class="img-rounded" src="images/four_dollars.png"></p>
-->
        
        </div>
      
        <div class="col-md-4">
          <h2 class="text-center">RESULTS</h2>
          
          <table class="table table-condensed">
            <thead>
              <th>Day</th>
              <th>Probability Distribution</th>
            </thead>
            <tbody>
              <tr>
                <td>Monday (x<sub>0</sub>)</td>
                <td>
                  <strong>Sun -</strong> 70%, <strong>Cloud/Fog -</strong> 70%, <strong>Rain -</strong> 0%</td>
              </tr>
              <tr>
                <td>Tuesday (x<sub>1</sub>)</td>
                <td><strong>Sun -</strong> 51.14%, <strong>Cloud/Fog -</strong> 22.12%, <strong>Rain -</strong> 26.74%</td>
              </tr>
              <tr>
                <td>Wednesday (x<sub>2</sub>)</td>
                <td><strong>Sun -</strong> 48.868%, <strong>Cloud/Fog -</strong> 15.465%, <strong>Rain -</strong> 35.667%</td>
              </tr>
              <tr>
                <td>Thursday (x<sub>3</sub>)</td>
                <td><strong>Sun -</strong> 47.755%, <strong>Cloud/Fog -</strong> 14.138%, <strong>Rain -</strong> 38.107%</td>
              </tr>
              <tr>
                <td>Friday (x<sub>4</sub>)</td>
                <td><strong>Sun -</strong> 47.432%, <strong>Cloud/Fog -</strong> 13.823%, <strong>Rain -</strong> 38.745%</td>
              </tr>
            </tbody>
          </table>
          
<!--
          <table class="table table-condensed">
            <thead>
              <th></th>
              <th>Probability of Winning</th>
              <th>
                <tr></tr>
                <tr>
                  <td><strong>Amount Gambled</strong></td>
                  <td>$0</td>
                  <td>$5</td>
                </tr>
              </th>
            </thead>
            <tbody>
              <tr>
                <td>$1</td>
                <td>0.12345</td>
                <td>0.12345</td>
              </tr>
              <tr>
                <td>$2</td>
                <td>0.12345</td>
                <td>0.12345</td>
              </tr>
              <tr>
                <td>$3</td>
                <td>0.12345</td>
                <td>0.12345</td>
              </tr>
              <tr>
                <td>$4</td>
                <td>0.12345</td>
                <td>0.12345</td>
              </tr>
              <tr>
                <td>$5</td>
                <td>0.12345</td>
                <td>0.12345</td>
              </tr>
            </tbody>
          </table>
-->
          
          <h2 class="text-center">CONCLUSION</h2>
          <p>
            The Markov chain is a good application to predict the outcome of certain events, such as gambling,
            but not for all instances, such as weather. There are many factors that affect the weather:
            climate change, humidity, etc. It is difficult to determine the percentages of sunny, foggy, and
            rain on a current day, specifically finding initial probability vector. Additionally, as the chain
            for the weather is continued, it converges to a consistent probability which is not how weather behaves.
            However, gambling is a more contained system that is based on the stochastic matrix of the machine.
            The results show that the bid is higher, the probability to win is higher and vise-versa. Everything 
            is predetermined by which machine is used and the amount of money by the user matching the consistent
            probability of 99 trials. Ultimately, it depends on the consistency of the system that allows how
            accurate the Markov chain can be.
          </p>
          
          <h2 class="text-center">SUMMARY</h2>
          <p>
            The Markov chain is used to predict the outcome of events by using a stochastic matrix, based on previous 
            data, and multiplying it to some initial data. Doing this one time will yield a probability vector that
            can be used to predict the next outcome. However, doing this multiple times will yield a probability 
            vector that can predict even further, that is only accurate depending on the given system. This explains
            the difference between the weather and gambling example. Overall, the Markov chain has the potential of
            estimating the approaching result.
          </p>
          
          <h2 class="text-center">SOURCES</h2> 
          
        </div>
      </div>
    </div>
    <script src="http://netdna.bootstrapcdn.com/bootstrap/3.0.2/js/bootstrap.min.js"></script>
  </body>
</html>